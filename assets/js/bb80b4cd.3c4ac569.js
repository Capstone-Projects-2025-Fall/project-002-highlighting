"use strict";(self.webpackChunkcreate_project_docs=self.webpackChunkcreate_project_docs||[]).push([[4260],{28453:(e,i,t)=>{t.d(i,{R:()=>o,x:()=>a});var n=t(96540);const r={},s=n.createContext(r);function o(e){const i=n.useContext(s);return n.useMemo((function(){return"function"==typeof e?e(i):{...i,...e}}),[i,e])}function a(e){let i;return i=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:o(e.components),n.createElement(s.Provider,{value:i},e.children)}},94768:(e,i,t)=>{t.r(i),t.d(i,{assets:()=>c,contentTitle:()=>a,default:()=>p,frontMatter:()=>o,metadata:()=>n,toc:()=>d});const n=JSON.parse('{"id":"system-architecture/component-overview","title":"Component Overview","description":"Client Side (TypeScript)","source":"@site/docs/system-architecture/component-overview.md","sourceDirName":"system-architecture","slug":"/system-architecture/component-overview","permalink":"/project-002-highlighting/docs/system-architecture/component-overview","draft":false,"unlisted":false,"editUrl":"https://github.com/Capstone-Projects-2025-Fall/project-002-highlighting/edit/main/documentation/docs/system-architecture/component-overview.md","tags":[],"version":"current","lastUpdatedBy":"Sley Chery","sidebarPosition":6,"frontMatter":{"sidebar_position":6},"sidebar":"docsSidebar","previous":{"title":"Version Control","permalink":"/project-002-highlighting/docs/system-architecture/version-control"},"next":{"title":"API Specification","permalink":"/project-002-highlighting/docs/category/api-specification"}}');var r=t(74848),s=t(28453);const o={sidebar_position:6},a="Component Overview",c={},d=[{value:"Client Side (TypeScript)",id:"client-side-typescript",level:2},{value:"Responsibilities:",id:"responsibilities",level:3},{value:"Components &amp; Interfaces:",id:"components--interfaces",level:3},{value:"Media Devices Interface",id:"media-devices-interface",level:4},{value:"Media Recorder Interface",id:"media-recorder-interface",level:4},{value:"AI Model (Client-Side Layer)",id:"ai-model-client-side-layer",level:4},{value:"Server Side (Node.js, .mjs)",id:"server-side-nodejs-mjs",level:2},{value:"Responsibilities:",id:"responsibilities-1",level:3},{value:"Components &amp; Interfaces:",id:"components--interfaces-1",level:3},{value:"WebSocket Server Interface",id:"websocket-server-interface",level:4},{value:"Audio Processing Module (FFmpeg)",id:"audio-processing-module-ffmpeg",level:4},{value:"Whisper AI API",id:"whisper-ai-api",level:4},{value:"Classification Module (Server-Side AI Model Layer)",id:"classification-module-server-side-ai-model-layer",level:4},{value:"Database Layer (Future Integration)",id:"database-layer-future-integration",level:2},{value:"Responsibilities:",id:"responsibilities-2",level:3},{value:"Interfaces:",id:"interfaces",level:3},{value:"Data Storage Interface",id:"data-storage-interface",level:4},{value:"Query Interface",id:"query-interface",level:4}];function l(e){const i={h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",p:"p",strong:"strong",...(0,s.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(i.header,{children:(0,r.jsx)(i.h1,{id:"component-overview",children:"Component Overview"})}),"\n",(0,r.jsx)(i.h2,{id:"client-side-typescript",children:"Client Side (TypeScript)"}),"\n",(0,r.jsx)(i.h3,{id:"responsibilities",children:"Responsibilities:"}),"\n",(0,r.jsx)(i.p,{children:"Captures audio from the user\u2019s microphone.\nRecords and packages the audio stream for transfer.\nSends audio data to the backend server via WebSocket.\nReceives transcription and classification results from the server.\nUpdates the AAC board by highlighting relevant pictographic labels based on the returned results."}),"\n",(0,r.jsx)(i.h3,{id:"components--interfaces",children:"Components & Interfaces:"}),"\n",(0,r.jsx)(i.h4,{id:"media-devices-interface",children:"Media Devices Interface"}),"\n",(0,r.jsxs)(i.p,{children:[(0,r.jsx)(i.strong,{children:"Function"}),": Requests access to the user\u2019s microphone.\n",(0,r.jsx)(i.strong,{children:"Input"}),": User permission to access device.\n",(0,r.jsx)(i.strong,{children:"Output"}),": Live audio stream object."]}),"\n",(0,r.jsx)(i.h4,{id:"media-recorder-interface",children:"Media Recorder Interface"}),"\n",(0,r.jsxs)(i.p,{children:[(0,r.jsx)(i.strong,{children:"Function"}),": Controls audio recording (start, stop).\n",(0,r.jsx)(i.strong,{children:"Input"}),": Audio stream from Media Devices.\n",(0,r.jsx)(i.strong,{children:"Output"}),": Encoded audio chunks.\n",(0,r.jsx)(i.strong,{children:"Interface"}),": Sends audio chunks via WebSocket to the server."]}),"\n",(0,r.jsx)(i.h4,{id:"ai-model-client-side-layer",children:"AI Model (Client-Side Layer)"}),"\n",(0,r.jsxs)(i.p,{children:[(0,r.jsx)(i.strong,{children:"Function"}),": Receives classification results from server.\n",(0,r.jsx)(i.strong,{children:"Input"}),": Transcribed text + pictographic labels.\n",(0,r.jsx)(i.strong,{children:"Output"}),": Highlighting of AAC board with relevant pictographs."]}),"\n",(0,r.jsx)(i.h2,{id:"server-side-nodejs-mjs",children:"Server Side (Node.js, .mjs)"}),"\n",(0,r.jsx)(i.h3,{id:"responsibilities-1",children:"Responsibilities:"}),"\n",(0,r.jsx)(i.p,{children:"Accepts incoming audio streams from client over WebSocket.\nConverts raw audio data into a format compatible with Whisper AI.\nRequests transcription from Whisper API.\nSends back transcription and pictographic classifications to the client."}),"\n",(0,r.jsx)(i.h3,{id:"components--interfaces-1",children:"Components & Interfaces:"}),"\n",(0,r.jsx)(i.h4,{id:"websocket-server-interface",children:"WebSocket Server Interface"}),"\n",(0,r.jsxs)(i.p,{children:[(0,r.jsx)(i.strong,{children:"Function"}),": Receives audio streams from client, returns transcription data.\n",(0,r.jsx)(i.strong,{children:"Input"}),": Encoded audio chunks from client.\n",(0,r.jsx)(i.strong,{children:"Output"}),": Transcribed text + classification results."]}),"\n",(0,r.jsx)(i.h4,{id:"audio-processing-module-ffmpeg",children:"Audio Processing Module (FFmpeg)"}),"\n",(0,r.jsxs)(i.p,{children:[(0,r.jsx)(i.strong,{children:"Function"}),": Converts audio format from WebM to PCM.\n",(0,r.jsx)(i.strong,{children:"Input"}),": Raw audio chunks from client.\n",(0,r.jsx)(i.strong,{children:"Output"}),": PCM data with WAV header."]}),"\n",(0,r.jsx)(i.h4,{id:"whisper-ai-api",children:"Whisper AI API"}),"\n",(0,r.jsxs)(i.p,{children:[(0,r.jsx)(i.strong,{children:"Function"}),": Performs speech-to-text transcription.\n",(0,r.jsx)(i.strong,{children:"Input"}),": WAV file (PCM encoded audio).\n",(0,r.jsx)(i.strong,{children:"Output"}),": Transcription (JSON, plain text, or SRT) with metadata such as timestamps."]}),"\n",(0,r.jsx)(i.h4,{id:"classification-module-server-side-ai-model-layer",children:"Classification Module (Server-Side AI Model Layer)"}),"\n",(0,r.jsxs)(i.p,{children:[(0,r.jsx)(i.strong,{children:"Function"}),": Maps transcribed words to pictographic labels.\n",(0,r.jsx)(i.strong,{children:"Input"}),": Text transcription.\n",(0,r.jsx)(i.strong,{children:"Output"}),": List of pictographs + context-sensitive highlighting data for client."]}),"\n",(0,r.jsx)(i.h2,{id:"database-layer-future-integration",children:"Database Layer (Future Integration)"}),"\n",(0,r.jsx)(i.h3,{id:"responsibilities-2",children:"Responsibilities:"}),"\n",(0,r.jsx)(i.p,{children:"Stores user transcripts, audio metadata, and classification outputs.\nMaintains logs for repeated use and system improvement.\nSupports personalized AAC board adaptation over time."}),"\n",(0,r.jsx)(i.h3,{id:"interfaces",children:"Interfaces:"}),"\n",(0,r.jsx)(i.h4,{id:"data-storage-interface",children:"Data Storage Interface"}),"\n",(0,r.jsxs)(i.p,{children:[(0,r.jsx)(i.strong,{children:"Input"}),": Transcriptions, pictograph mappings, user interaction logs.\n",(0,r.jsx)(i.strong,{children:"Output"}),": Stored and retrievable records."]}),"\n",(0,r.jsx)(i.h4,{id:"query-interface",children:"Query Interface"}),"\n",(0,r.jsxs)(i.p,{children:[(0,r.jsx)(i.strong,{children:"Function"}),": Provides past transcripts and context to the AI model for more accurate predictions.\n",(0,r.jsx)(i.strong,{children:"Output"}),": Context-aware classification suggestions."]})]})}function p(e={}){const{wrapper:i}={...(0,s.R)(),...e.components};return i?(0,r.jsx)(i,{...e,children:(0,r.jsx)(l,{...e})}):l(e)}}}]);