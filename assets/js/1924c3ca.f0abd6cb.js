"use strict";(self.webpackChunkcreate_project_docs=self.webpackChunkcreate_project_docs||[]).push([[9141],{28453:(e,n,s)=>{s.d(n,{R:()=>a,x:()=>r});var t=s(96540);const i={},o=t.createContext(i);function a(e){const n=t.useContext(o);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:a(e.components),t.createElement(o.Provider,{value:n},e.children)}},89210:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>c,contentTitle:()=>r,default:()=>d,frontMatter:()=>a,metadata:()=>t,toc:()=>l});const t=JSON.parse('{"id":"system-architecture/Sequence-Diagrams","title":"Sequence-Diagrams","description":"Use Case 1 - Audio transcription for hearing loss","source":"@site/docs/system-architecture/Sequence-Diagrams.md","sourceDirName":"system-architecture","slug":"/system-architecture/Sequence-Diagrams","permalink":"/project-002-highlighting/docs/system-architecture/Sequence-Diagrams","draft":false,"unlisted":false,"editUrl":"https://github.com/Capstone-Projects-2025-Fall/project-002-highlighting/edit/main/documentation/docs/system-architecture/Sequence-Diagrams.md","tags":[],"version":"current","lastUpdatedBy":"JudeP2","sidebarPosition":5,"frontMatter":{"sidebar_position":5},"sidebar":"docsSidebar","previous":{"title":"Class Diagrams","permalink":"/project-002-highlighting/docs/system-architecture/Class-diagrams"},"next":{"title":"Version Control","permalink":"/project-002-highlighting/docs/system-architecture/version-control"}}');var i=s(74848),o=s(28453);const a={sidebar_position:5},r=void 0,c={},l=[{value:"Use Case 1 - Audio transcription for hearing loss",id:"use-case-1---audio-transcription-for-hearing-loss",level:2},{value:"Use Case 2 - Sentence Formation",id:"use-case-2---sentence-formation",level:2},{value:"Use Case 3 - Contextual based prediction",id:"use-case-3---contextual-based-prediction",level:2},{value:"Use Case 4 - Toggling microphone when not in a conversation",id:"use-case-4---toggling-microphone-when-not-in-a-conversation",level:2}];function h(e){const n={h2:"h2",li:"li",ol:"ol",p:"p",strong:"strong",...(0,o.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.h2,{id:"use-case-1---audio-transcription-for-hearing-loss",children:"Use Case 1 - Audio transcription for hearing loss"}),"\n",(0,i.jsx)("img",{width:"706",height:"583",alt:"Usecase1SD",src:"https://github.com/user-attachments/assets/9a7ef916-9626-4f14-abf2-fac6d2d0df2b"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Figure 1."})," Use case 1 Sequence Diagram"]}),"\n",(0,i.jsx)("i",{children:" User wants to communicate with a user that is hearing impaired "}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:"User will download and open the app"}),"\n",(0,i.jsx)(n.li,{children:"User will toggle the microphone on and speak into the recording"}),"\n",(0,i.jsx)(n.li,{children:"Recording will show a transcription of what was said and can be replayed"}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"use-case-2---sentence-formation",children:"Use Case 2 - Sentence Formation"}),"\n",(0,i.jsx)("img",{width:"821",height:"493",alt:"Usecase2SD",src:"https://github.com/user-attachments/assets/0e335715-eb59-4bfb-b247-db4cba7139bb"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Figure 2."})," Use case 2 Sequence Diagram"]}),"\n",(0,i.jsx)("i",{children:" Speech-impaired user wants to communicate with a user via AAC Board "}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:"User will download and open the app"}),"\n",(0,i.jsx)(n.li,{children:"User will press on tiles to form sentence with highlighted tiles changing upon each tile pressed"}),"\n",(0,i.jsx)(n.li,{children:"User will click on audio output to translate text to speech"}),"\n",(0,i.jsx)(n.li,{children:"AAC Board will relay text to speech"}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"use-case-3---contextual-based-prediction",children:"Use Case 3 - Contextual based prediction"}),"\n",(0,i.jsxs)(n.p,{children:["**",(0,i.jsx)("img",{width:"835",height:"554",alt:"Usecase3SD",src:"https://github.com/user-attachments/assets/9693f02d-30eb-48f4-9a60-8ffd30c7d5f7"})]}),"\n",(0,i.jsx)(n.p,{children:"Figure 3.** Use case 3 Sequence Diagram"}),"\n",(0,i.jsx)("i",{children:"As a user, it is important that the device can display options to me based on what is being spoken by the other person in conversation "}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:"A parent asks their child a question"}),"\n",(0,i.jsx)(n.li,{children:"AAC device would pick up the question through audio input (speech to text)"}),"\n",(0,i.jsx)(n.li,{children:"Displays suggestive options to form a sentence that would function as a relevant response."}),"\n",(0,i.jsx)(n.li,{children:"Child's mom could ask what the child wants for dinner with the board actively listening"}),"\n",(0,i.jsx)(n.li,{children:"Board will highlight several food word options to choose from"}),"\n",(0,i.jsx)(n.li,{children:"User chooses best option according to their preference"}),"\n",(0,i.jsx)(n.li,{children:"User plays tiles section out loud for parent to hear and acknowledge"}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"use-case-4---toggling-microphone-when-not-in-a-conversation",children:"Use Case 4 - Toggling microphone when not in a conversation"}),"\n",(0,i.jsx)("img",{width:"3730",height:"3840",alt:"usecase8",src:"https://github.com/user-attachments/assets/c97b3d59-34a5-44d9-ac0a-e9e05b762daf"}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Figure 4."})," Use case 4 Sequence Diagram"]}),"\n",(0,i.jsx)("i",{children:"As a user, it is important that I can toggle on and off the microphone when I am not in a conversation. "}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:"When the user first launches the application the microphone will be on by default for fast conversation engagement"}),"\n",(0,i.jsx)(n.li,{children:"If the user wishes to toggle off their microphone for any reason they can hit the button and the icon will change indicating the microphone is off"}),"\n"]})]})}function d(e={}){const{wrapper:n}={...(0,o.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(h,{...e})}):h(e)}}}]);