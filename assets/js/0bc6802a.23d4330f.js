"use strict";(self.webpackChunkcreate_project_docs=self.webpackChunkcreate_project_docs||[]).push([[3845],{28453:(e,n,i)=>{i.d(n,{R:()=>d,x:()=>l});var r=i(96540);const s={},c=r.createContext(s);function d(e){const n=r.useContext(c);return r.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:d(e.components),r.createElement(c.Provider,{value:n},e.children)}},77774:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>o,contentTitle:()=>l,default:()=>a,frontMatter:()=>d,metadata:()=>r,toc:()=>t});const r=JSON.parse('{"id":"api-specification/Highlighting","title":"Highlighting","description":"This describes the functionality, state variables, and methods available in the AudioTranscription React component.","source":"@site/docs/api-specification/Highlighting.md","sourceDirName":"api-specification","slug":"/api-specification/Highlighting","permalink":"/project-002-highlighting/docs/api-specification/Highlighting","draft":false,"unlisted":false,"editUrl":"https://github.com/Capstone-Projects-2025-Fall/project-002-highlighting/edit/main/documentation/docs/api-specification/Highlighting.md","tags":[],"version":"current","lastUpdatedBy":"Sley Chery","sidebarPosition":1,"frontMatter":{"sidebar_position":1},"sidebar":"docsSidebar","previous":{"title":"API Specification","permalink":"/project-002-highlighting/docs/category/api-specification"},"next":{"title":"Test Procedures","permalink":"/project-002-highlighting/docs/category/test-procedures"}}');var s=i(74848),c=i(28453);const d={sidebar_position:1},l="Highlighting",o={},t=[{value:"<code>Component: AudioTranscription</code>",id:"component-audiotranscription",level:3},{value:"<code>Socket: socket</code>",id:"socket-socket",level:3},{value:"<code>State: record</code>",id:"state-record",level:3},{value:"<code>State: transcript</code>",id:"state-transcript",level:3},{value:"<code>State: audioURL</code>",id:"state-audiourl",level:3},{value:"<code>Ref: chunksRef</code>",id:"ref-chunksref",level:3},{value:"<code>Ref: mediaRecorderRef</code>",id:"ref-mediarecorderref",level:3},{value:"<code>useEffect: Initialize MediaRecorder</code>",id:"useeffect-initialize-mediarecorder",level:3},{value:"<code>Event: ondataavailable</code>",id:"event-ondataavailable",level:4},{value:"<code>Event: onstop</code>",id:"event-onstop",level:4},{value:"<code>Function: startRecording()</code>",id:"function-startrecording",level:3},{value:"<code>Function: stopRecording()</code>",id:"function-stoprecording",level:3},{value:"<code>useEffect: Socket Listener</code>",id:"useeffect-socket-listener",level:3},{value:"<code>Render</code>",id:"render",level:3},{value:"<code>Module: server</code>",id:"module-server",level:3},{value:"<code>Variable: app</code>",id:"variable-app",level:3},{value:"<code>Variable: server</code>",id:"variable-server",level:3},{value:"<code>Variable: io</code>",id:"variable-io",level:3},{value:"<code>Variable: __filename</code>",id:"variable-__filename",level:3},{value:"<code>Variable: __dirname</code>",id:"variable-__dirname",level:3},{value:"<code>Middleware: express.static</code>",id:"middleware-expressstatic",level:3},{value:"<code>Variable: openai</code>",id:"variable-openai",level:3},{value:"<code>Function: server.listen()</code>",id:"function-serverlisten",level:3},{value:"<code>Event: connection</code>",id:"event-connection",level:3},{value:"<code>Variable: ffmpeg</code>",id:"variable-ffmpeg",level:4},{value:"<code>Variable: audioBuffer</code>",id:"variable-audiobuffer",level:4},{value:"<code>Variable: isProcessing</code>",id:"variable-isprocessing",level:4},{value:"<code>Variable: fileCounter</code>",id:"variable-filecounter",level:4},{value:"<code>Variable: silenceCounter</code>",id:"variable-silencecounter",level:4},{value:"<code>Constant: CHUNK_DURATION</code>",id:"constant-chunk_duration",level:4},{value:"<code>Function: initializeFFmpeg()</code>",id:"function-initializeffmpeg",level:3},{value:"<code>Event: stderr.data</code>",id:"event-stderrdata",level:4},{value:"<code>Event: close</code>",id:"event-close",level:4},{value:"<code>Event: error</code>",id:"event-error",level:4},{value:"<code>Event: stdout.data</code>",id:"event-stdoutdata",level:3},{value:"<code>Function: createWavFile(pcmData)</code>",id:"function-createwavfilepcmdata",level:3},{value:"<code>Function: processAudio()</code>",id:"function-processaudio",level:3},{value:"<code>Variable: interval</code>",id:"variable-interval",level:3},{value:"<code>Event: audio-chunk</code>",id:"event-audio-chunk",level:3},{value:"<code>Event: disconnect</code>",id:"event-disconnect",level:3}];function h(e){const n={code:"code",h1:"h1",h3:"h3",h4:"h4",header:"header",hr:"hr",li:"li",p:"p",strong:"strong",ul:"ul",...(0,c.R)(),...e.components},{Details:i}=n;return i||function(e,n){throw new Error("Expected "+(n?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("Details",!0),(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"highlighting",children:"Highlighting"})}),"\n",(0,s.jsx)(n.h1,{id:"audio-transcription",children:(0,s.jsx)(n.strong,{children:"Audio Transcription"})}),"\n",(0,s.jsxs)(n.p,{children:["This describes the functionality, state variables, and methods available in the ",(0,s.jsx)(n.code,{children:"AudioTranscription"})," React component."]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h3,{id:"component-audiotranscription",children:(0,s.jsx)(n.code,{children:"Component: AudioTranscription"})}),"\n",(0,s.jsx)(i,{open:"True",children:(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"A React component that records audio from the user\u2019s microphone and sends it to a transcription server using Socket.io."}),"\n",(0,s.jsx)(n.li,{children:"Displays real-time transcription results and provides playback for recorded audio."}),"\n"]})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h3,{id:"socket-socket",children:(0,s.jsx)(n.code,{children:"Socket: socket"})}),"\n",(0,s.jsx)(i,{open:"True",children:(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Establishes a WebSocket connection to the transcription server."}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Type:"})," ",(0,s.jsx)(n.code,{children:"Socket"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Server:"})," ",(0,s.jsx)(n.code,{children:"http://localhost:5000"})]}),"\n"]})}),"\n",(0,s.jsx)(n.h3,{id:"state-record",children:(0,s.jsx)(n.code,{children:"State: record"})}),"\n",(0,s.jsx)(i,{open:"True",children:(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Tracks whether recording is currently active."}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Type:"})," ",(0,s.jsx)(n.code,{children:"boolean"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Purpose:"})," Controls the recording state of the component."]}),"\n"]})}),"\n",(0,s.jsx)(n.h3,{id:"state-transcript",children:(0,s.jsx)(n.code,{children:"State: transcript"})}),"\n",(0,s.jsx)(i,{open:"True",children:(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Stores transcribed text received from the server."}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Type:"})," ",(0,s.jsx)(n.code,{children:"string"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Purpose:"})," Accumulates live transcription data from the socket connection."]}),"\n"]})}),"\n",(0,s.jsx)(n.h3,{id:"state-audiourl",children:(0,s.jsx)(n.code,{children:"State: audioURL"})}),"\n",(0,s.jsx)(i,{open:"True",children:(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Holds the object URL for the most recently recorded audio blob."}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Type:"})," ",(0,s.jsx)(n.code,{children:"string | null"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Purpose:"})," Enables local playback of the last recording."]}),"\n"]})}),"\n",(0,s.jsx)(n.h3,{id:"ref-chunksref",children:(0,s.jsx)(n.code,{children:"Ref: chunksRef"})}),"\n",(0,s.jsx)(i,{open:"True",children:(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Stores raw audio chunks as they are recorded."}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Type:"})," ",(0,s.jsx)(n.code,{children:"React.MutableRefObject<Blob[]>"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Purpose:"})," Maintains recorded audio data between renders."]}),"\n"]})}),"\n",(0,s.jsx)(n.h3,{id:"ref-mediarecorderref",children:(0,s.jsx)(n.code,{children:"Ref: mediaRecorderRef"})}),"\n",(0,s.jsx)(i,{open:"True",children:(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Holds the instance of the MediaRecorder API."}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Type:"})," ",(0,s.jsx)(n.code,{children:"React.MutableRefObject<MediaRecorder | null>"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Purpose:"})," Controls recording start, stop, and event handling."]}),"\n"]})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h3,{id:"useeffect-initialize-mediarecorder",children:(0,s.jsx)(n.code,{children:"useEffect: Initialize MediaRecorder"})}),"\n",(0,s.jsxs)(i,{open:"True",children:[(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Requests microphone access from the browser."}),"\n",(0,s.jsx)(n.li,{children:"Sets up the MediaRecorder and its event handlers once permission is granted."}),"\n"]}),(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Precondition:"})}),(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Browser must support the MediaDevices API."}),"\n"]}),(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Postcondition:"})}),(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"MediaRecorder instance is created and ready for use."}),"\n"]}),(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Throws:"})}),(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Error if microphone access is denied or unavailable."}),"\n"]})]}),"\n",(0,s.jsx)(n.h4,{id:"event-ondataavailable",children:(0,s.jsx)(n.code,{children:"Event: ondataavailable"})}),"\n",(0,s.jsx)(i,{open:"True",children:(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Triggered whenever an audio chunk becomes available."}),"\n",(0,s.jsx)(n.li,{children:"Sends the chunk buffer to the transcription server via Socket.io."}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Parameter:"})," ",(0,s.jsx)(n.code,{children:"e (BlobEvent)"})," \u2013 Contains the recorded audio data."]}),"\n"]})}),"\n",(0,s.jsx)(n.h4,{id:"event-onstop",children:(0,s.jsx)(n.code,{children:"Event: onstop"})}),"\n",(0,s.jsx)(i,{open:"True",children:(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Triggered when recording stops."}),"\n",(0,s.jsx)(n.li,{children:"Combines all collected chunks into a single audio Blob and generates a playback URL."}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Parameter:"})," ",(0,s.jsx)(n.code,{children:"e (Event)"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Postcondition:"})," Playback URL is created and chunk buffer is cleared."]}),"\n"]})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h3,{id:"function-startrecording",children:(0,s.jsx)(n.code,{children:"Function: startRecording()"})}),"\n",(0,s.jsxs)(i,{open:"True",children:[(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Begins audio recording and streams data to the server every few seconds."}),"\n"]}),(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Precondition:"})}),(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"MediaRecorder must be initialized and microphone access granted."}),"\n"]}),(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Postcondition:"})}),(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["Recording state set to ",(0,s.jsx)(n.code,{children:"true"})," and MediaRecorder starts capturing audio."]}),"\n"]}),(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Throws:"})}),(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Error if MediaRecorder is not initialized or unavailable."}),"\n"]})]}),"\n",(0,s.jsx)(n.h3,{id:"function-stoprecording",children:(0,s.jsx)(n.code,{children:"Function: stopRecording()"})}),"\n",(0,s.jsxs)(i,{open:"True",children:[(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Stops active audio recording and finalizes the audio blob."}),"\n"]}),(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Precondition:"})}),(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["MediaRecorder must be in ",(0,s.jsx)(n.code,{children:"recording"})," state."]}),"\n"]}),(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Postcondition:"})}),(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["Recording state set to ",(0,s.jsx)(n.code,{children:"false"})," and playback URL generated."]}),"\n"]}),(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Throws:"})}),(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Error if MediaRecorder is not currently recording."}),"\n"]})]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h3,{id:"useeffect-socket-listener",children:(0,s.jsx)(n.code,{children:"useEffect: Socket Listener"})}),"\n",(0,s.jsx)(i,{open:"True",children:(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["Listens for ",(0,s.jsx)(n.code,{children:'"transcript"'})," events from the server."]}),"\n",(0,s.jsx)(n.li,{children:"Updates the transcript text in real time."}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Precondition:"})," Socket connection must be active."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Postcondition:"})," Transcribed text appears dynamically in the UI."]}),"\n"]})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h3,{id:"render",children:(0,s.jsx)(n.code,{children:"Render"})}),"\n",(0,s.jsx)(i,{open:"True",children:(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["Renders the component UI, including:","\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Start and Stop recording buttons."}),"\n",(0,s.jsx)(n.li,{children:"Recording status display."}),"\n",(0,s.jsx)(n.li,{children:"Real-time transcript text."}),"\n",(0,s.jsx)(n.li,{children:"Audio playback control (if available)."}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Returns:"})," A JSX.Element"]}),"\n"]})}),"\n",(0,s.jsx)(n.h1,{id:"audio-transcription-server",children:(0,s.jsx)(n.strong,{children:"Audio Transcription Server"})}),"\n",(0,s.jsx)(n.h1,{id:"module-documentation",children:"Module Documentation"}),"\n",(0,s.jsxs)(n.p,{children:["This describes the functionality, configuration, and events of the ",(0,s.jsx)(n.strong,{children:"Audio Transcription Server"}),", a Node.js application that processes live audio via Socket.io and transcribes it using OpenAI\u2019s Whisper API."]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h3,{id:"module-server",children:(0,s.jsx)(n.code,{children:"Module: server"})}),"\n",(0,s.jsx)(i,{open:"True",children:(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"A Node.js server that handles real-time audio transcription using Socket.io and OpenAI's Whisper API."}),"\n",(0,s.jsx)(n.li,{children:"Receives audio chunks from clients, processes them with FFmpeg, converts them to WAV format, and sends them to Whisper for transcription."}),"\n"]})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h3,{id:"variable-app",children:(0,s.jsx)(n.code,{children:"Variable: app"})}),"\n",(0,s.jsx)(i,{open:"True",children:(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Type:"})," ",(0,s.jsx)(n.code,{children:"express.Application"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Description:"})," The main Express application object responsible for handling HTTP requests and serving static files."]}),"\n"]})}),"\n",(0,s.jsx)(n.h3,{id:"variable-server",children:(0,s.jsx)(n.code,{children:"Variable: server"})}),"\n",(0,s.jsx)(i,{open:"True",children:(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Type:"})," ",(0,s.jsx)(n.code,{children:"http.Server"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Description:"})," HTTP server instance created from the Express application."]}),"\n"]})}),"\n",(0,s.jsx)(n.h3,{id:"variable-io",children:(0,s.jsx)(n.code,{children:"Variable: io"})}),"\n",(0,s.jsx)(i,{open:"True",children:(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Type:"})," ",(0,s.jsx)(n.code,{children:"Server"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Description:"})," Socket.io server bound to the HTTP server with CORS enabled, used for real-time communication with clients."]}),"\n"]})}),"\n",(0,s.jsx)(n.h3,{id:"variable-__filename",children:(0,s.jsx)(n.code,{children:"Variable: __filename"})}),"\n",(0,s.jsx)(i,{open:"True",children:(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Type:"})," ",(0,s.jsx)(n.code,{children:"string"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Description:"})," Absolute path to the current module file."]}),"\n"]})}),"\n",(0,s.jsx)(n.h3,{id:"variable-__dirname",children:(0,s.jsx)(n.code,{children:"Variable: __dirname"})}),"\n",(0,s.jsx)(i,{open:"True",children:(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Type:"})," ",(0,s.jsx)(n.code,{children:"string"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Description:"})," Absolute path to the directory containing the current module."]}),"\n"]})}),"\n",(0,s.jsx)(n.h3,{id:"middleware-expressstatic",children:(0,s.jsx)(n.code,{children:"Middleware: express.static"})}),"\n",(0,s.jsx)(i,{open:"True",children:(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Serves static files from the current directory."}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Purpose:"})," Allows clients to access frontend resources directly from the same server."]}),"\n"]})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h3,{id:"variable-openai",children:(0,s.jsx)(n.code,{children:"Variable: openai"})}),"\n",(0,s.jsx)(i,{open:"True",children:(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Type:"})," ",(0,s.jsx)(n.code,{children:"OpenAI"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Description:"})," Initialized OpenAI API client used to perform audio transcriptions with Whisper."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Throws:"})," Error if ",(0,s.jsx)(n.code,{children:"OPENAI_API_KEY"})," is not found in environment variables."]}),"\n"]})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h3,{id:"function-serverlisten",children:(0,s.jsx)(n.code,{children:"Function: server.listen()"})}),"\n",(0,s.jsx)(i,{open:"True",children:(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Description:"})," Starts the HTTP and Socket.io server."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Postcondition:"})," The server is running and listening for connections on port ",(0,s.jsx)(n.code,{children:"5000"}),"."]}),"\n"]})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h3,{id:"event-connection",children:(0,s.jsx)(n.code,{children:"Event: connection"})}),"\n",(0,s.jsx)(i,{open:"True",children:(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Emitter:"})," ",(0,s.jsx)(n.code,{children:"io"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Description:"})," Triggered when a new client connects via Socket.io."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Parameter:"})," ",(0,s.jsx)(n.code,{children:"socket (Socket)"})," \u2014 Represents the client\u2019s active connection."]}),"\n"]})}),"\n",(0,s.jsx)(n.h4,{id:"variable-ffmpeg",children:(0,s.jsx)(n.code,{children:"Variable: ffmpeg"})}),"\n",(0,s.jsx)(i,{open:"True",children:(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Type:"})," ",(0,s.jsx)(n.code,{children:"ChildProcess"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Description:"})," Child process running FFmpeg for live audio conversion from WebM to PCM format."]}),"\n"]})}),"\n",(0,s.jsx)(n.h4,{id:"variable-audiobuffer",children:(0,s.jsx)(n.code,{children:"Variable: audioBuffer"})}),"\n",(0,s.jsx)(i,{open:"True",children:(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Type:"})," ",(0,s.jsx)(n.code,{children:"Buffer"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Description:"})," Holds accumulated PCM audio data for processing and transcription."]}),"\n"]})}),"\n",(0,s.jsx)(n.h4,{id:"variable-isprocessing",children:(0,s.jsx)(n.code,{children:"Variable: isProcessing"})}),"\n",(0,s.jsx)(i,{open:"True",children:(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Type:"})," ",(0,s.jsx)(n.code,{children:"boolean"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Description:"})," Indicates whether the server is currently processing an audio chunk."]}),"\n"]})}),"\n",(0,s.jsx)(n.h4,{id:"variable-filecounter",children:(0,s.jsx)(n.code,{children:"Variable: fileCounter"})}),"\n",(0,s.jsx)(i,{open:"True",children:(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Type:"})," ",(0,s.jsx)(n.code,{children:"number"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Description:"})," Increments with each processed audio chunk to ensure unique filenames."]}),"\n"]})}),"\n",(0,s.jsx)(n.h4,{id:"variable-silencecounter",children:(0,s.jsx)(n.code,{children:"Variable: silenceCounter"})}),"\n",(0,s.jsx)(i,{open:"True",children:(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Type:"})," ",(0,s.jsx)(n.code,{children:"number"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Description:"})," Tracks consecutive empty or too-small audio buffers to manage silence detection."]}),"\n"]})}),"\n",(0,s.jsx)(n.h4,{id:"constant-chunk_duration",children:(0,s.jsx)(n.code,{children:"Constant: CHUNK_DURATION"})}),"\n",(0,s.jsx)(i,{open:"True",children:(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Type:"})," ",(0,s.jsx)(n.code,{children:"number"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Value:"})," ",(0,s.jsx)(n.code,{children:"4000"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Description:"})," Defines the interval (in milliseconds) between automatic audio processing cycles."]}),"\n"]})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h3,{id:"function-initializeffmpeg",children:(0,s.jsx)(n.code,{children:"Function: initializeFFmpeg()"})}),"\n",(0,s.jsxs)(i,{open:"True",children:[(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Description:"})," Initializes and configures the FFmpeg process to receive WebM audio input and output raw PCM data."]}),"\n"]}),(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Precondition:"})}),(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"FFmpeg must be installed and available in the system PATH."}),"\n"]}),(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Postcondition:"})}),(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"ffmpeg"})," variable contains an active process ready to handle audio input."]}),"\n"]}),(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Throws:"})}),(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Error if FFmpeg is missing or encounters a startup failure."}),"\n"]})]}),"\n",(0,s.jsx)(n.h4,{id:"event-stderrdata",children:(0,s.jsx)(n.code,{children:"Event: stderr.data"})}),"\n",(0,s.jsx)(i,{open:"True",children:(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Logs FFmpeg error messages for debugging."}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Parameter:"})," ",(0,s.jsx)(n.code,{children:"data (Buffer)"})," \u2014 Contains FFmpeg stderr output."]}),"\n"]})}),"\n",(0,s.jsx)(n.h4,{id:"event-close",children:(0,s.jsx)(n.code,{children:"Event: close"})}),"\n",(0,s.jsx)(i,{open:"True",children:(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Triggered when FFmpeg terminates."}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Parameter:"})," ",(0,s.jsx)(n.code,{children:"code (number)"})," \u2014 Exit code from the FFmpeg process."]}),"\n"]})}),"\n",(0,s.jsx)(n.h4,{id:"event-error",children:(0,s.jsx)(n.code,{children:"Event: error"})}),"\n",(0,s.jsx)(i,{open:"True",children:(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Handles FFmpeg errors gracefully and logs them."}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Parameter:"})," ",(0,s.jsx)(n.code,{children:"err (Error)"})]}),"\n"]})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h3,{id:"event-stdoutdata",children:(0,s.jsx)(n.code,{children:"Event: stdout.data"})}),"\n",(0,s.jsx)(i,{open:"True",children:(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Triggered when FFmpeg outputs PCM audio data."}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Parameter:"})," ",(0,s.jsx)(n.code,{children:"chunk (Buffer)"})," \u2014 PCM audio chunk."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Postcondition:"})," Data is appended to the ",(0,s.jsx)(n.code,{children:"audioBuffer"}),"."]}),"\n"]})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h3,{id:"function-createwavfilepcmdata",children:(0,s.jsx)(n.code,{children:"Function: createWavFile(pcmData)"})}),"\n",(0,s.jsx)(i,{open:"True",children:(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Description:"})," Creates a valid WAV file from raw PCM audio data by manually writing the WAV header."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Parameter:"})," ",(0,s.jsx)(n.code,{children:"pcmData (Buffer)"})," \u2014 The raw PCM audio input."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Returns:"})," ",(0,s.jsx)(n.code,{children:"Buffer"})," \u2014 A complete WAV file ready for saving or transcription."]}),"\n"]})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h3,{id:"function-processaudio",children:(0,s.jsx)(n.code,{children:"Function: processAudio()"})}),"\n",(0,s.jsxs)(i,{open:"True",children:[(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Description:"})," Processes buffered PCM audio, converts it to WAV, and sends it to OpenAI\u2019s Whisper for transcription."]}),"\n"]}),(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Precondition:"})}),(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Sufficient audio must exist in the buffer."}),"\n"]}),(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Postcondition:"})}),(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["Transcription results are sent to the client via ",(0,s.jsx)(n.code,{children:'socket.emit("transcript")'}),"."]}),"\n"]}),(0,s.jsx)(n.p,{children:(0,s.jsx)(n.strong,{children:"Throws:"})}),(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Error if file writing fails or the OpenAI API returns an error."}),"\n"]}),(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Async:"})," Yes"]})]}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h3,{id:"variable-interval",children:(0,s.jsx)(n.code,{children:"Variable: interval"})}),"\n",(0,s.jsx)(i,{open:"True",children:(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Type:"})," ",(0,s.jsx)(n.code,{children:"NodeJS.Timeout"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Description:"})," Interval timer that triggers ",(0,s.jsx)(n.code,{children:"processAudio()"})," every ",(0,s.jsx)(n.code,{children:"CHUNK_DURATION"})," milliseconds."]}),"\n"]})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h3,{id:"event-audio-chunk",children:(0,s.jsx)(n.code,{children:"Event: audio-chunk"})}),"\n",(0,s.jsx)(i,{open:"True",children:(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Emitter:"})," ",(0,s.jsx)(n.code,{children:"socket"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Description:"})," Receives audio data chunks from clients and pipes them into the FFmpeg process."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Parameter:"})," ",(0,s.jsx)(n.code,{children:"data (ArrayBuffer)"})," \u2014 Raw audio data from the client."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Throws:"})," Error if FFmpeg stdin is unwritable or encounters a write failure."]}),"\n"]})}),"\n",(0,s.jsx)(n.hr,{}),"\n",(0,s.jsx)(n.h3,{id:"event-disconnect",children:(0,s.jsx)(n.code,{children:"Event: disconnect"})}),"\n",(0,s.jsx)(i,{open:"True",children:(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Emitter:"})," ",(0,s.jsx)(n.code,{children:"socket"})]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Description:"})," Cleans up server-side resources when a client disconnects."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Postcondition:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"FFmpeg process terminated."}),"\n",(0,s.jsx)(n.li,{children:"Processing interval cleared."}),"\n",(0,s.jsx)(n.li,{children:"Audio buffer reset."}),"\n"]}),"\n"]}),"\n"]})})]})}function a(e={}){const{wrapper:n}={...(0,c.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(h,{...e})}):h(e)}}}]);