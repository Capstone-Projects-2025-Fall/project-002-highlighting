---
sidebar_position: 2
---
# Integration tests


## Use Case 1 - Audio transcription for hearing loss
<i> User wants to communicate with a user that is hearing impaired </i>


1. Download the app locally or visit deployed website on vercel
2. Toggle the microphone on for person conversing to user to speak while microphone is on and recording on board
3. Transcription will be shown of whats being said



## Use Case 2 - Sentence Formation
<i> Speech-impaired user wants to communicate with a user via AAC Board </i>


1. Open application locally or through Vercel deployment
2. Press on tiles to form a sentence, tiles will be highlighted after based on suggested words
3. Click on the audio output button to translate the tiles text to speech
4. Board will say the tiles chosen outloud for others to hear

## Use Case 3 - Contextual based prediction 
<i>As a user, it is important that the device can display options to me based on what is being spoken by the other person in conversation </i>

1. Parent or person in coversation with asks a question
2. AAC board picks up the question through audio input
3. Board formulates suggested words that could be a response
4. Parent/person in conversation can ask what you want for dinner and the board picks this up
5. Board will highlight relevant food tiles to choose from
6. Choose highlighted tile that best fits preference for response.

## Use Case 4 - Toggling microphone when not in a conversation
<i>As a user, it is important that I can toggle on and off the microphone when I am not in a conversation. </i>

1. Open the application and notice that the microphone is on and actively listening for fast conversation engagement 
2. Toggle the microphone off and on depending on if you are in a conversation or not by hitting the stop button to stop and play button to record